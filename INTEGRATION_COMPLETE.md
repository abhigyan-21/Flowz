# Pipeline & Data Store Integration Summary

## âœ… What Has Been Connected

You now have a **complete flood prediction pipeline** that:

1. **Executes a 4-stage workflow** (Ingestion â†’ LISFLOOD-OS â†’ LISFLOOD-FP â†’ AI Model)
2. **Stores all results** in organized run directories in `data_store/`
3. **Provides easy access** to predictions via Python utilities and API endpoints
4. **Integrates seamlessly** with your backend and frontend

---

## ğŸ“ Folder Structure (Updated)

```
Flowz/
â”œâ”€â”€ pipeline/                          â† Pipeline code
â”‚   â”œâ”€â”€ config.py                      âœ… Configuration & path management
â”‚   â”œâ”€â”€ orchestrator.py                âœ… Main pipeline executor
â”‚   â”œâ”€â”€ data_bridge.py                 âœ… Data access utilities
â”‚   â”œâ”€â”€ PIPELINE_GUIDE.md              âœ… Detailed documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ 01_ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ingestion.py               âœ… Stage 1: Data loading
â”‚   â”‚
â”‚   â”œâ”€â”€ 02_lisflood_os/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ lisflood_os.py             âœ… Stage 2: 1D simulation
â”‚   â”‚
â”‚   â”œâ”€â”€ 03_lisflood_fp/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ lisflood_fp.py             âœ… Stage 3: 2D simulation
â”‚   â”‚
â”‚   â””â”€â”€ 04_ai_model/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ inference.py               âœ… Stage 4: AI predictions (FIXED)
â”‚
â”œâ”€â”€ data_store/                        â† Pipeline execution results
â”‚   â””â”€â”€ runs/
â”‚       â”œâ”€â”€ run_2026_02_10_1114_FIXED/
â”‚       â”‚   â”œâ”€â”€ 01_ingestion/
â”‚       â”‚   â”œâ”€â”€ 02_lisflood_os/
â”‚       â”‚   â”œâ”€â”€ 03_lisflood_fp/
â”‚       â”‚   â”œâ”€â”€ 04_predictions/        âœ… Contains final_map.tif & risk_summary.json
â”‚       â”‚   â””â”€â”€ pipeline_report.json
â”‚       â”‚
â”‚       â””â”€â”€ run_2026_02_10_1150_MANUAL/
â”‚           â””â”€â”€ [same structure]
â”‚
â”œâ”€â”€ PIPELINE_INTEGRATION_EXAMPLE.py    âœ… Backend API integration example
â”‚
â”œâ”€â”€ backend/                           â† Your FastAPI backend
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ routers/
â”‚           â””â”€â”€ [Add flood_integration.py here - see example]
â”‚
â”œâ”€â”€ src/                               â† Your React frontend
â”‚   â””â”€â”€ [Components receive data from API]
â”‚
â””â”€â”€ [Other existing files]
```

---

## ğŸš€ Quick Start

### 1. Run the Pipeline

```bash
cd Flowz/pipeline
python orchestrator.py --suffix MY_TEST
```

**Output**: Creates `data_store/runs/run_2026_02_10_XXXX_MY_TEST/` with all predictions

### 2. Access Results in Python

```python
from pipeline.data_bridge import DataBridge

# Get latest predictions
data = DataBridge.get_latest_run_data()
risk_score = data['predictions']['risk_summary']['riskScore']
print(f"Risk Score: {risk_score}")
```

### 3. Integrate with Backend API

```python
# In backend/app/routers/flood_integration.py (copy from PIPELINE_INTEGRATION_EXAMPLE.py)
@router.get("/api/flood/predictions/latest")
async def get_predictions():
    data = DataBridge.get_latest_run_data()
    return data['predictions']['risk_summary']
```

### 4. Display in Frontend

```javascript
// In your React component
const [forecast, setForecast] = useState(null);

useEffect(() => {
    fetch('/api/flood/predictions/latest')
        .then(r => r.json())
        .then(data => setForecast(data));
}, []);

return <div>Risk Level: {forecast?.severityLevel}</div>;
```

---

## ğŸ”„ Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER / SCHEDULER                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PIPELINE ORCHESTRATOR (orchestrator.py)                       â”‚
â”‚  â”œâ”€ Validates configuration                                     â”‚
â”‚  â”œâ”€ Creates run directory structure                             â”‚
â”‚  â””â”€ Calls each stage sequentially                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
    â”‚ Stage  â”‚    â”‚ Stage   â”‚   â”‚ Stage  â”‚   â”‚ Stage  â”‚
    â”‚   01   â”‚    â”‚   02    â”‚   â”‚   03   â”‚   â”‚   04   â”‚
    â”‚Ingst.  â”‚â”€â”€â”€â–¶â”‚ LISF-OS â”‚â”€â”€â–¶â”‚LISF-FP â”‚â”€â”€â–¶â”‚   AI   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                                                   â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    DATA STORE (RESULTS)          â”‚
                           â”‚  data_store/runs/run_XXXX_YYYY/  â”‚
                           â”‚  â”œâ”€ 01_ingestion/                â”‚
                           â”‚  â”œâ”€ 02_lisflood_os/              â”‚
                           â”‚  â”œâ”€ 03_lisflood_fp/              â”‚
                           â”‚  â”œâ”€ 04_predictions/              â”‚
                           â”‚  â”‚  â”œâ”€ final_map.tif             â”‚
                           â”‚  â”‚  â”œâ”€ risk_summary.json         â”‚
                           â”‚  â””â”€ pipeline_report.json         â”‚
                           â”‚                                   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    DATA BRIDGE             â”‚
                           â”‚  (data_bridge.py)          â”‚
                           â”‚  - Load run data           â”‚
                           â”‚  - List runs               â”‚
                           â”‚  - Export formats          â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  BACKEND API               â”‚
                           â”‚  (flood_integration.py)    â”‚
                           â”‚  - /api/flood/predictions  â”‚
                           â”‚  - /api/flood/runs/list    â”‚
                           â”‚  - /api/flood/pipeline/run â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  FRONTEND (React)          â”‚
                           â”‚  - Display forecasts       â”‚
                           â”‚  - Show flood maps         â”‚
                           â”‚  - List historical runs    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Key Features

### Configuration Management (`config.py`)
- âœ… Automatic path resolution (works on any system)
- âœ… Runs directory structure creation
- âœ… Environment-agnostic configuration

### Pipeline Execution (`orchestrator.py`)
- âœ… Sequential 4-stage execution
- âœ… Isolated run directories (no conflicts)
- âœ… Execution logging and reporting
- âœ… Error handling with reports

### Data Access (`data_bridge.py`)
- âœ… Load full run data in one call
- âœ… List all historical runs
- âœ… Export as GeoJSON for mapping
- âœ… Get latest predictions instantly

### Backend Integration (`PIPELINE_INTEGRATION_EXAMPLE.py`)
- âœ… 9 REST API endpoints
- âœ… Background pipeline execution
- âœ… Health checks
- âœ… Multiple data export formats

---

## ğŸ”§ How to Complete Integration

### Step 1: Backend Integration (5 minutes)

```bash
# Copy the integration example
cp PIPELINE_INTEGRATION_EXAMPLE.py backend/app/routers/flood_integration.py

# Edit backend/app/main.py, add:
from app.routers import flood_integration
app.include_router(flood_integration.router)
```

### Step 2: Test the API

```bash
# Start your backend
python backend/main.py

# Test API
curl http://localhost:8000/api/flood/health
curl http://localhost:8000/api/flood/runs/list
```

### Step 3: Frontend Integration

```javascript
// In your React components
import { useEffect, useState } from 'react';

export function FloodForecast() {
    const [predictions, setPredictions] = useState(null);
    
    useEffect(() => {
        fetch('/api/flood/predictions/latest')
            .then(r => r.json())
            .then(setPredictions);
    }, []);
    
    if (!predictions) return <div>Loading...</div>;
    
    return (
        <div className="forecast">
            <h2>{predictions.location}</h2>
            <p>Risk Score: {predictions.riskScore}</p>
            <p>Severity: {predictions.severityLevel}</p>
            <p>Water Level: {predictions.waterLevel}m</p>
        </div>
    );
}
```

### Step 4: Automate Pipeline Runs (Optional)

```python
# Use APScheduler or Celery
from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler()

@scheduler.scheduled_job('cron', hour='*/6')  # Every 6 hours
def run_flood_pipeline():
    from pipeline.orchestrator import run_pipeline
    from pipeline.config import Config
    
    run_id = Config.get_run_id("SCHEDULED")
    run_pipeline(run_id=run_id)

scheduler.start()
```

---

## ğŸ“‹ Run Lifecycle

### Creating a New Run

```
trigger orchestrator.py
    â†“
Config.ensure_run_structure(run_id)
    â†“
â”œâ”€ 01_ingestion/ âœ“
â”œâ”€ 02_lisflood_os/ âœ“
â”œâ”€ 03_lisflood_fp/ âœ“
â”œâ”€ 04_predictions/ âœ“
â””â”€ pipeline_report.json âœ“
    â†“
All stages execute
    â†“
Results written to respective directories
    â†“
DataBridge can load and access the data
```

### Accessing Run Data

```
DataBridge.get_run_data("run_2026_02_10_1114_FIXED")
    â†“
Loads from:
â”œâ”€ 01_ingestion/ingestion_metadata.json
â”œâ”€ 02_lisflood_os/lisflood_os_results.json
â”œâ”€ 03_lisflood_fp/lisflood_fp_results.json
â”œâ”€ 04_predictions/risk_summary.json
â””â”€ pipeline_report.json
    â†“
Returns structured dictionary with all data
```

---

## ğŸ¯ What's Ready Now

| Feature | Status | Location |
|---------|--------|----------|
| Pipeline configuration | âœ… Done | `pipeline/config.py` |
| 4-stage pipeline | âœ… Done | `pipeline/orchestrator.py` + stages |
| Data storage structure | âœ… Done | `data_store/runs/` |
| Fixed hardcoded paths | âœ… Done | `pipeline/04_ai_model/inference.py` |
| Data access utilities | âœ… Done | `pipeline/data_bridge.py` |
| API integration example | âœ… Done | `PIPELINE_INTEGRATION_EXAMPLE.py` |
| Documentation | âœ… Done | `pipeline/PIPELINE_GUIDE.md` |
| Backend integration | â³ Your turn | Copy integration example to backend |
| Frontend visualization | â³ Your turn | Use API endpoints in React |

---

## ğŸ“ Next Steps for You

1. **Copy integration example** to your backend
2. **Add API routes** to expose pipeline data
3. **Update frontend** to fetch from `/api/flood/` endpoints
4. **Test end-to-end** by running pipeline and viewing results
5. **Customize** pipeline stages with your actual models

---

## ğŸ†˜ Troubleshooting

### "ModuleNotFoundError: No module named 'config'"
```bash
# Solution: Run from pipeline directory
cd Flowz/pipeline
python orchestrator.py
```

### "ValueError: Run not found"
```bash
# Solution: Check run ID format
python orchestrator.py --list  # Lists all available runs
```

### Data appearing in wrong location
```bash
# Solution: Verify configuration
python -c "from config import Config; print(Config.DATA_STORE_DIR)"
```

---

## ğŸ“ Support Resources

- **Pipeline Guide**: [pipeline/PIPELINE_GUIDE.md](pipeline/PIPELINE_GUIDE.md)
- **Integration Example**: [PIPELINE_INTEGRATION_EXAMPLE.py](PIPELINE_INTEGRATION_EXAMPLE.py)
- **API Documentation**: Built-in FastAPI /docs endpoint

---

**Status**: âœ… Pipeline fully connected and ready to use!  
**Created**: 2026-02-10  
**Last Updated**: 2026-02-10
